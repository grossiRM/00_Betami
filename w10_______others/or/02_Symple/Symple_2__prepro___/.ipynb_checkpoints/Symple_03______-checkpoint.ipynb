{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "635fafe0-3c1e-45bd-bbb3-d0a806a0a767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gp\n",
    "from pathlib import Path\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from rasterio import features\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from flopy.utils.gridintersect import GridIntersect\n",
    "import flopy\n",
    "import os \n",
    "from shapely.geometry import Point, LineString\n",
    "import pandas as pd\n",
    "from flopy.utils import Raster\n",
    "from flopy.utils.gridgen import Gridgen \n",
    "from flopy.utils.gridintersect import GridIntersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c321e2f-718e-4089-9d83-315133139ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = Path('../data/sgn/')         # rch.columns   # rhc.tail()   # rch.plot(column = 'RCH_mmy', legend=True)\n",
    "rch = gp.read_file(datapath / 'shp' / 'Recharge_4.shp')\n",
    "bot2_rast = rasterio.open(datapath/ 'raster' / 'Bott_L2_fix.tif') \n",
    "rastermeta = bot2_rast.meta.copy()\n",
    "rastermeta.update(compress='lzw') \n",
    "rchpolygons = ((geom,value) for geom, value in zip(rch.geometry, rch.RCH_mmy))        # rch.geometry no error (?!)\n",
    "with rasterio.open(datapath/ 'raster' / 'rch.tif', 'w+', **rastermeta) as ofp:        \n",
    "    out_arr = ofp.read(1)  \n",
    "    rchraster = features.rasterize(shapes=rchpolygons, fill=-9999, out=out_arr, transform=ofp.transform)\n",
    "    ofp.write_band(1,rchraster)\n",
    "with rasterio.open(datapath/ 'raster' / 'rch.tif') as src:   # just confirm, BUT SET..... rch\n",
    "    rch = src.read(1)\n",
    "rch[rch<-1] = np.nan                    # plt.imshow(rch)  # plt.colorbar()\n",
    "rch.to_csv(\"Symple_p/01_rch.csv\") \n",
    "rch.to_csv(\"Symple_p/01_rch.dat\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d8f71a-34d6-4155-8777-de3fdb9d1ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "geology = gp.read_file(datapath / 'shp' / 'Geology_250000_clip.shp')         # datapath = Path('../data/sgn/')\n",
    "geology.to_csv(\"Symple_p/02_geo.csv\") \n",
    "# geology.plot(column = 'LITOLOGIA', legend=True)                            # geology.columns\n",
    "geology['k'] = -999999\n",
    "geology.loc[geology.LITOLOGIA == 'Gravel and sand', 'k'] = 0.0045            # geology\n",
    "geology.loc[geology.LITOLOGIA == 'Gravel, sand and silt', 'k'] = 0.0023\n",
    "assert geology.k.min()>0 \n",
    "geopolygons = ((geom,value) for geom, value in zip(geology.geometry, geology.k))\n",
    "with rasterio.open(datapath/ 'raster' / 'k_field0.tif', 'w+', **rastermeta) as ofp: \n",
    "    out_arr = ofp.read(1)   \n",
    "    georaster = features.rasterize(shapes=geopolygons, fill=-9999, out=out_arr, transform=ofp.transform)\n",
    "    ofp.write_band(1,georaster)\n",
    "with rasterio.open(datapath/ 'raster' / 'k_field0.tif') as src:\n",
    "    k0 = src.read(1)\n",
    "k0[k0<-1] = np.nan           #plt.imshow(k0)          #plt.colorbar()\n",
    "k1 = np.ones_like(k0) * 1e-8 # aquitard\n",
    "k2 = np.ones_like(k0) * 2.3e-3 # deep aquifer\n",
    "with rasterio.open(datapath/ 'raster' / 'k_field1.tif', 'w+', **rastermeta) as ofp:\n",
    "    ofp.write_band(1, k1)     \n",
    "with rasterio.open(datapath/ 'raster' / 'k_field2.tif', 'w+', **rastermeta) as ofp:\n",
    "    ofp.write_band(1, k2)     \n",
    "shutil.copy('../data/sgn/raster/k_field0.tif', 'Symple_p/03_k_field0.tif')\n",
    "shutil.copy('../data/sgn/raster/k_field1.tif', 'Symple_p/04_k_field1.tif')\n",
    "shutil.copy('../data/sgn/raster/k_field2.tif', 'Symple_p/05_k_field2.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66e2afe0-3636-4719-afc8-18fecdc6cb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Symple_03'\n",
    "sim = 'mf6.exe'\n",
    "sim = flopy.mf6.MFSimulation(exe_name=sim, version=\"mf6\", continue_=True)   \n",
    "gwf = flopy.mf6.ModflowGwf(sim, modelname=model_name, save_flows=True, print_flows=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e884169f-adb5-4a17-8622-f03284aa9f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "riv = gp.read_file(datapath / 'shp' / 'River_Lambro.shp')  # riv\n",
    "riv1 = riv.iloc[0].geometry\n",
    "rivpts = [Point(i) for i in riv1.coords]\n",
    "newpt = Point(rivpts[0].coords[0][0],rivpts[0].coords[0][1]+150)           # _______ starting point outside the domain  \n",
    "rivpts.insert(0,newpt)                                                      \n",
    "newpt = Point(rivpts[-1].coords[0][0]+150,rivpts[-1].coords[0][1]-150)     # _______ ending point each outside the domain\n",
    "rivpts.append(newpt)  \n",
    "rivsegs = []\n",
    "totpts = len(rivpts)/10\n",
    "previous_seg = 0\n",
    "for i in range(1,10):\n",
    "    tmppts = rivpts[previous_seg:int(i*totpts)]\n",
    "    previous_seg = int(i*totpts)-1\n",
    "    rivsegs.append(LineString(zip([c.coords[0][0] for c in tmppts],[c.coords[0][1] for c in tmppts])))\n",
    "tmppts = rivpts[previous_seg:-1]\n",
    "rivsegs.append(LineString(zip([c.coords[0][0] for c in tmppts],[c.coords[0][1]for c in tmppts]))) # ax = geology.plot(column='k', legend=True) # riv.plot(ax=ax)\n",
    "# \n",
    "riv_divided = gp.GeoDataFrame({'geometry':rivsegs,'segname': [i+1+1000 for i in range(len(rivsegs))]},crs=riv.crs)  \n",
    "riv_points = gp.GeoDataFrame({'geometry':rivpts,'ptname' : np.arange(len(rivpts))},crs=riv.crs)  \n",
    "# ax=riv_divided.plot(column='segname', legend=True, figsize=(4,5))  # riv_points.plot(column='ptname', ax=ax)\n",
    "# \n",
    "riv_divided ['from_id'] = [i+1000 for i in range(len(riv_divided))]\n",
    "riv_divided.loc[0, 'from_id'] = 0\n",
    "riv_divided ['to_id'] = [i+2+1000 for i in range(len(riv_divided))]\n",
    "riv_divided.loc[9, 'to_id'] = 0\n",
    "riv_divided['streamwid'] = 15                                             #  width\n",
    "riv_divided.to_file(datapath / 'shp' / 'River_Lambro_segmented.shp')\n",
    "riv_divided.to_csv(\"Symple_p/06_riv_divided.csv\")                        \n",
    "riv_points.to_csv(\"Symple_p/07_riv_points.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c51bbb2-8bc5-4c16-af3c-f9673ec4b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(datapath/ 'raster' / 'DTM_domain.tif') as src:\n",
    "    modtop = src.read(1)\n",
    "with rasterio.open(datapath/ 'raster' / 'Bott_L1_fix.tif') as src:\n",
    "    bot1 = src.read(1)\n",
    "with rasterio.open(datapath/ 'raster' / 'Bott_L2_fix.tif') as src:\n",
    "    bot2 = src.read(1)               # plt.imshow(bot1) # plt.colorbar()\n",
    "    \n",
    "bot2_rast = rasterio.open(datapath/ 'raster' / 'Bott_L2_fix.tif') \n",
    "meta_lay3 = bot2_rast.meta.copy()\n",
    "meta_lay3.update(compress='lzw') \n",
    "bot2_rast.close()\n",
    "\n",
    "bot3 = bot2-60.  #plt.imshow(bot3)   # plt.colorbar()\n",
    "with rasterio.open(datapath/ 'raster' / 'Bott_L3_fix.tif', 'w+', **meta_lay3) as ofp:\n",
    "    ofp.write_band(1, bot3)       \n",
    "with rasterio.open(datapath/ 'raster' / 'Bott_L3_fix.tif') as src:\n",
    "    bot3 = src.read(1)               # plt.imshow(bot3)    # plt.colorbar()           \n",
    "\n",
    "shutil.copy('../data/sgn/raster/Bott_L1_fix.tif', 'Symple_p/08_Bott_L1_fix.tif')\n",
    "shutil.copy('../data/sgn/raster/Bott_L2_fix.tif', 'Symple_p/09_Bott_L2_fix.tif')\n",
    "shutil.copy('../data/sgn/raster/Bott_L3_fix.tif', 'Symple_p/10_Bott_L3_fix.tif')\n",
    "\n",
    "rivfile = str(datapath / 'shp' / 'River_Lambro_segmented.shp')                    \n",
    "inriv = gp.read_file(rivfile)                                           # Segment identification \n",
    "inriv['obsname'] = [f'seg_{i}' for i in inriv.segname]\n",
    "inriv.head()\n",
    "rivsegfile = str(datapath / 'csv' / 'river_segments.csv')\n",
    "inriv[['segname', 'obsname']].to_csv(rivsegfile)\n",
    "riv_points.to_csv(\"Symple_p/11_SFR_points.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2176fa8e-7f2c-436c-9323-62237b906387",
   "metadata": {},
   "outputs": [],
   "source": [
    "wells = gp.read_file(datapath / 'shp' / 'wells.shp')           # ax = domain.plot(facecolor=\"none\", edgecolor='black')         \n",
    "wells.WellName = wells.WellName.apply(lambda x: x.lower())     # wells.columns           # wells.plot( ax=ax)\n",
    "well_metadata = pd.read_csv(datapath / 'wells_with_elev.dat', index_col=0)       # _________________________ # *.dat\n",
    "well_metadata.to_csv(\"Symple_p/12_Wells.csv\")                                  # len(well_metadata)        # well_metadata.head()\n",
    "well_metadata = well_metadata.loc[well_metadata.q != 0]                          # q = 0  supressing         # len(well_metadata)\n",
    "well_metadata.head()\n",
    "well_metadata.to_csv(\"Symple_p/13_Wells.csv\")       # __________________________________________________\n",
    "well_data = well_metadata.merge(wells[['X','Y','WellName']], left_on='rootname', right_on='WellName')    # rootname | Wellname\n",
    "well_data = well_data.rename(columns = {'X':'x', 'Y':'y', 'laytop':'screen_top', 'laybot':'screen_botm'})\n",
    "well_data['datetime'] = '2021-01-01'                                 \n",
    "well_data['enddatetime'] = '2022-12-31'\n",
    "well_data.to_csv(\"Symple_p/14_Wells_Pump.csv\") # __________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53a56b3f-95e6-4e1c-ad32-58b836e5773e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_barrier, y_barrier = 1519614, 5031870\n",
    "DTM_raster= rasterio.open(datapath/ 'raster' / 'DTM_domain.tif')\n",
    "rDTM,cDTM = DTM_raster.index(x_barrier, y_barrier)\n",
    "DTM_barrier = modtop[rDTM,cDTM]\n",
    "Lay1_raster= rasterio.open(datapath/ 'raster' / 'Bott_L1_fix.tif')\n",
    "rLay1,cLay1 = Lay1_raster.index(x_barrier, y_barrier)\n",
    "bot1_barrier = bot1[rLay1,cLay1]\n",
    "rasterio.transform.rowcol(Lay1_raster.transform, x_barrier, y_barrier)       # must read unique coordinates\n",
    "#\n",
    "well_no_pumping = well_data.loc[well_data.q == 0].copy()\n",
    "well_no_pumping.loc[:,'screen_botm'] = -300            # set an arbitrarily low    # elevation for the screen bottom\n",
    "well_no_pumping.index = range(len(well_no_pumping))\n",
    "well_no_pumping[['q','x','y','boundname','screen_top','screen_botm', 'enddatetime','datetime','laymidpt']].to_csv(datapath / 'wells_zero.csv')\n",
    "well_data_2 = well_data.loc[well_data.q != 0].copy()\n",
    "well_data_2.loc[:,'datetime'] = '2022-01-01'\n",
    "well_data = pd.concat((well_data,well_data_2))  # ____________concat ______________ append \n",
    "well_data.to_csv(\"Symple_p/15_Wells_Pump.csv\") "
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1f28681-e7b1-4ddc-a939-7037c3944990",
   "metadata": {},
   "source": [
    "well_data = well_data.append(pd.DataFrame({'cellid':[np.nan],'q':[-30/1000],'x':[x_barrier],'y':[y_barrier],          # ERR\n",
    "                              'boundname':['barrier'],'screen_top':[DTM_barrier],'screen_botm':[bot1_barrier],\n",
    "                              'datetime':['2022-01-01'],'enddatetime':['2022-12-31'],\n",
    "                              'laymidpt':[np.mean((DTM_barrier, bot1_barrier))],'layer':[0],'cell':[np.nan],'WellName':['barrier']}))\n",
    "well_data[['q','x','y','boundname','screen_top','screen_botm', 'enddatetime','datetime','laymidpt']].to_csv(datapath / 'wells_nonzero.csv')\n",
    "well_data.to_csv(\"Symple_p/16_Wells_Pump.Barrier.csv\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4dedc2-b26f-4512-9202-fa75be1e9147",
   "metadata": {},
   "source": [
    "# **Making dats**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cefa6fb3-433e-4fa8-b0f8-12f37577da5b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d3e368-f55a-45a9-9414-e76913789a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b959d72f-d8a8-4e09-98b6-31d53533e753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4471efb-2fc7-4c3a-b073-3323b18be450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "97709e80-f0f1-4926-bbb4-f73a12975e25",
   "metadata": {},
   "source": [
    "config_data['simulation']            = dict() 1 \n",
    "config_data['model']                 = dict() 2\n",
    "config_data['intermediate_data']     = dict() 3\n",
    "config_data['setup_grid']            = dict() 4\n",
    "config_data['dis']                   = dict() 5\n",
    "config_data['tdis']                  = dict() 6\n",
    "config_data['ic']                    = dict() 7\n",
    "config_data['wel']                   = dict() 8\n",
    "config_data['oc']                    = dict() 9\n",
    "config_data['npf']                   = dict() 10\n",
    "config_data['rch']                   = dict() 11\n",
    "config_data['sfr']                   = dict() 12\n",
    "config_data['ims']                   = dict() 13\n",
    "config_data['obs']                   = dict() 14"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8bb8ec05-9c76-49e9-a68c-a7c8a0c4efa7",
   "metadata": {},
   "source": [
    "# Zone and Grid\n",
    "\n",
    "zones_shpfile = os.path.join(datapath, 'shp', 'Geology_250000_clip.shp')\n",
    "ix = GridIntersect(gwf.modelgrid)\n",
    "\n",
    "riv = gp.read_file(datapath / 'shp' / 'River_Lambro.shp')  # riv\n",
    "riv1 = riv.iloc[0].geometry\n",
    "rivpts = [Point(i) for i in riv1.coords]\n",
    "newpt = Point(rivpts[0].coords[0][0],rivpts[0].coords[0][1]+150)           # _______ starting point outside the domain  \n",
    "rivpts.insert(0,newpt)                                                      \n",
    "newpt = Point(rivpts[-1].coords[0][0]+150,rivpts[-1].coords[0][1]-150)     # _______ ending point each outside the domain\n",
    "rivpts.append(newpt)  \n",
    "rivsegs = []\n",
    "totpts = len(rivpts)/10\n",
    "previous_seg = 0\n",
    "for i in range(1,10):\n",
    "    tmppts = rivpts[previous_seg:int(i*totpts)]\n",
    "    previous_seg = int(i*totpts)-1\n",
    "    rivsegs.append(LineString(zip([c.coords[0][0] for c in tmppts],[c.coords[0][1] for c in tmppts])))\n",
    "tmppts = rivpts[previous_seg:-1]\n",
    "rivsegs.append(LineString(zip([c.coords[0][0] for c in tmppts],[c.coords[0][1] for c in tmppts])))\n",
    "# ax = geology.plot(column='k', legend=True)\n",
    "# riv.plot(ax=ax)\n",
    "riv_divided = gp.GeoDataFrame({'geometry':rivsegs,'segname': [i+1+1000 for i in range(len(rivsegs))]},crs=riv.crs)  # _______\n",
    "riv_points = gp.GeoDataFrame({'geometry':rivpts,'ptname' : np.arange(len(rivpts))},crs=riv.crs)  # __________________________\n",
    "# ax=riv_divided.plot(column='segname', legend=True, figsize=(4,5))\n",
    "# riv_points.plot(column='ptname', ax=ax)\n",
    "riv_divided ['from_id'] = [i+1000 for i in range(len(riv_divided))]\n",
    "riv_divided.loc[0, 'from_id'] = 0\n",
    "riv_divided ['to_id'] = [i+2+1000 for i in range(len(riv_divided))]\n",
    "riv_divided.loc[9, 'to_id'] = 0\n",
    "riv_divided['streamwid'] = 15                                             #  width\n",
    "riv_divided.to_file(datapath / 'shp' / 'River_Lambro_segmented.shp')\n",
    "\n",
    "riv_shpfile = os.path.join(datapath, 'shp', 'River_stages_polyline.shp')  #_________________________________________________________________ #  PAR\n",
    "riv_shapes = sf.Reader(riv_shpfile).shapes()\n",
    "riv_spd=[]    \n",
    "for i in range(len(riv_shapes)):\n",
    "    shp = riv_shapes[i]\n",
    "    stage = sf.Reader(riv_shpfile).record(i)[0] - 0.4          # the shapefile records contain the stage in the first attribute \"column\";\n",
    "    cellids = ix.intersect(shp).cellids                        # get the intersect \n",
    "    cond = 0.001\n",
    "    rbot = stage - 1.0\n",
    "    for icpl in cellids:\n",
    "        riv_spd.append(((0, icpl), stage, cond, rbot, 'riv'))  # [cellid, stage, cond, rbot, aux, boundname]\n",
    "        \n",
    "riv = flopy.mf6.ModflowGwfriv(gwf, stress_period_data = riv_spd, boundnames = True)\n",
    "\n",
    "riv.set_all_data_external()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "486290d9-e34c-44e0-a656-42836e3eca9a",
   "metadata": {},
   "source": [
    "x,y = domain.geometry[0].exterior.coords.xy      # _________________________ Extra\n",
    "xul, yul = x[np.argmin(x)],y[np.argmin(x)]\n",
    "xtop, ytop = x[np.argmax(y)],y[np.argmax(y)]\n",
    "xll, yll = x[np.argmin(y)],y[np.argmin(y)]\n",
    "xlr,ylr = x[np.argmax(x)],y[np.argmax(x)]\n",
    "\n",
    "ax = domain.plot(color=None)\n",
    "ax.plot(xul,yul, 'x', ms=12)    # x mark\n",
    "ax.plot(xtop,ytop, 'o', ms=12)  # circle mark\n",
    "ax.plot(xll,yll,'*', ms=12)     # star mark\n",
    "ax.plot(xlr,ylr,'d', ms=12)     # diamond mark\n",
    "\n",
    "opp_over_hyp = np.abs(ytop-yul)/np.sqrt((xtop-xul)**2+(ytop-yul)**2)\n",
    "# opp_over_hyp\n",
    "theta = np.arcsin(opp_over_hyp)\n",
    "theta = float(theta * 180/np.pi)\n",
    "# theta\n",
    "length = np.round(np.sqrt((xll-xul)**2+(yll-yul)**2), decimals=-1)\n",
    "# length\n",
    "width = np.round(np.sqrt((xll-xlr)**2+(yll-ylr)**2), decimals=-1)\n",
    "# width"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
