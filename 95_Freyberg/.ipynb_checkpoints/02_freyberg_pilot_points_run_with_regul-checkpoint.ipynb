{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Freyberg pilot points to use regularization and see what happens...\n",
    "\n",
    "### With our first attempt at pilot points, we saw bad things.  So lets see if we can fix the problem by using regularization.\n",
    "\n",
    "Recall from Anderson et al. (2015) regularization adds an additional term to our total objective function:\n",
    "\n",
    "<img src=\"tik-reg_eq9.9.png\" style=\"float: center\">\n",
    "\n",
    "The first term to the right of the equals sign is the measurement objective function from\n",
    "Eqn (9.6), which is calculated as the sum of squared weighted residuals, where *n* residuals,\n",
    "*ri*, are calculated from hard knowledge and wi are their respective weights. The second\n",
    "term quantifies the penalty resulting from deviations from soft knowledge as the sum\n",
    "of *q* deviations from *j* soft knowledge conditions *fj*, where *fj* is a function of model parameters\n",
    "*p*. \n",
    "\n",
    "## A calibrated model, therefore, is found by minimizing both the measurement objective function (hard data) and the soft knowledge penalty.\n",
    "\n",
    "\n",
    "### Let's see how to do this in PEST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, shutil\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import flopy as flopy\n",
    "import pyemu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\15_REPOS\\00_BETAMI\\95_Freyberg\\freyberg_setup.py:1042: SyntaxWarning: invalid escape sequence '\\d'\n",
      "E:\\15_REPOS\\00_BETAMI\\95_Freyberg\\freyberg_setup.py:1053: SyntaxWarning: invalid escape sequence '\\d'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FloPy is using the following executable to run the model: mfnwt.exe\n",
      "\n",
      "                                  MODFLOW-NWT-SWR1 \n",
      "    U.S. GEOLOGICAL SURVEY MODULAR FINITE-DIFFERENCE GROUNDWATER-FLOW MODEL\n",
      "                             WITH NEWTON FORMULATION\n",
      "                             Version 1.0.9 07/01/2014                        \n",
      "                    BASED ON MODFLOW-2005 Version 1.11.0 08/08/2013                       \n",
      "\n",
      "                    SWR1 Version 1.03.0 08/30/2013                       \n",
      "\n",
      " Using NAME file: freyberg.nam \n",
      " Run start date and time (yyyy/mm/dd hh:mm:ss): 2025/06/11  9:18:00\n",
      "\n",
      " Solving:  Stress period:     1    Time step:     1    Groundwater-Flow Eqn.\n",
      " Solving:  Stress period:     2    Time step:     1    Groundwater-Flow Eqn.\n",
      " Solving:  Stress period:     3    Time step:     1    Groundwater-Flow Eqn.\n",
      " Run end date and time (yyyy/mm/dd hh:mm:ss): 2025/06/11  9:18:00\n",
      " Elapsed run time:  0.100 Seconds\n",
      "\n",
      "  Normal termination of simulation\n",
      "mp6.exe freyberg.mpsim\n",
      "Util2d:delr: resetting 'how' to external\n",
      "Util2d:delc: resetting 'how' to external\n",
      "Util2d:model_top: resetting 'how' to external\n",
      "Util2d:botm_layer_0: resetting 'how' to external\n",
      "Util2d:hk layer 1: resetting 'how' to external\n",
      "Util2d:vk: resetting 'how' to external\n",
      "Util2d:ss: resetting 'how' to external\n",
      "Util2d:sy: resetting 'how' to external\n",
      "Util2d:ibound_layer_0: resetting 'how' to external\n",
      "Util2d:strt_layer_0: resetting 'how' to external\n",
      "Util2d:rech_1: resetting 'how' to external\n",
      "Util2d:rech_2: resetting 'how' to external\n",
      "Util2d:rech_3: resetting 'how' to external\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\15_REPOS\\00_BETAMI\\95_Freyberg\\freyberg_setup.py:1042: SyntaxWarning: invalid escape sequence '\\d'\n",
      "E:\\15_REPOS\\00_BETAMI\\95_Freyberg\\freyberg_setup.py:1053: SyntaxWarning: invalid escape sequence '\\d'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to NoneType.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\flopy\\mbase.py:1439\u001b[0m, in \u001b[0;36mBaseModel.write_input\u001b[1;34m(self, SelPackList, check)\u001b[0m\n\u001b[0;32m   1438\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1439\u001b[0m     p\u001b[38;5;241m.\u001b[39mwrite_file(check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1440\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: ModflowWel.write_file() got an unexpected keyword argument 'check'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfreyberg_setup\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mfs\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m fs\u001b[38;5;241m.\u001b[39msetup_pest_pp()\n\u001b[0;32m      3\u001b[0m working_dir \u001b[38;5;241m=\u001b[39m fs\u001b[38;5;241m.\u001b[39mWORKING_DIR_PP\n\u001b[0;32m      4\u001b[0m pst_name \u001b[38;5;241m=\u001b[39m fs\u001b[38;5;241m.\u001b[39mPST_NAME_PP\n",
      "File \u001b[1;32mE:\\15_REPOS\\00_BETAMI\\95_Freyberg\\freyberg_setup.py:868\u001b[0m, in \u001b[0;36msetup_pest_pp\u001b[1;34m(make_porosity_tpl)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup_pest_pp\u001b[39m(make_porosity_tpl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 868\u001b[0m     setup_model(WORKING_DIR_PP)\n\u001b[0;32m    869\u001b[0m     os\u001b[38;5;241m.\u001b[39mchdir(WORKING_DIR_PP)\n\u001b[0;32m    871\u001b[0m     write_sfr_template(onepar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mE:\\15_REPOS\\00_BETAMI\\95_Freyberg\\freyberg_setup.py:164\u001b[0m, in \u001b[0;36msetup_model\u001b[1;34m(working_dir)\u001b[0m\n\u001b[0;32m    160\u001b[0m m\u001b[38;5;241m.\u001b[39mexternal_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m#m.oc.chedfm = \"(20f16.6)\"\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m#output_idx = m.output_fnames.index(\"freyberg.hds\")\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m#m.output_binflag[output_idx] = False\u001b[39;00m\n\u001b[1;32m--> 164\u001b[0m m\u001b[38;5;241m.\u001b[39mwrite_input()\n\u001b[0;32m    166\u001b[0m m\u001b[38;5;241m.\u001b[39mexe_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(m\u001b[38;5;241m.\u001b[39mmodel_ws,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmfnwt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    167\u001b[0m m\u001b[38;5;241m.\u001b[39mrun_model()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\flopy\\mbase.py:1441\u001b[0m, in \u001b[0;36mBaseModel.write_input\u001b[1;34m(self, SelPackList, check)\u001b[0m\n\u001b[0;32m   1439\u001b[0m             p\u001b[38;5;241m.\u001b[39mwrite_file(check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1440\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m-> 1441\u001b[0m             p\u001b[38;5;241m.\u001b[39mwrite_file()\n\u001b[0;32m   1442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1443\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pon \u001b[38;5;129;01min\u001b[39;00m SelPackList:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\flopy\\modflow\\mfwel.py:286\u001b[0m, in \u001b[0;36mModflowWel.write_file\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecify \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mversion \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmfnwt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 286\u001b[0m         f_wel\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSPECIFY \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphiramp\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m10.5g\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miunitramp\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m10d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstress_period_data\u001b[38;5;241m.\u001b[39mwrite_transient(f_wel)\n\u001b[0;32m    289\u001b[0m f_wel\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported format string passed to NoneType.__format__"
     ]
    }
   ],
   "source": [
    "import freyberg_setup as fs\n",
    "fs.setup_pest_pp()\n",
    "working_dir = fs.WORKING_DIR_PP\n",
    "pst_name = fs.PST_NAME_PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.plot_model(working_dir, pst_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Okay, we have a running PEST setup and model to work with - let's use a shortcut variable to tell pyemu that we want interrogate or look at this particular model.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(working_dir,pst_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the ``intro_to_regularization``, we talked about two common forms of Tikhonov regularization.  Here we will add both types to the control file.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's add a few preferred value equations for the recharge and well flux parameters.  First, let's use pyemu to tell us what parameter groups are in our PEST control file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# echo out what parameter groups are in the PEST control file\n",
    "pst.parameter_data.pargp.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See the pst at the beginning of the line of code?  That is the variable we defined above that has the PEST control file specified.  That is how pyemu knows which model to report on.\n",
    "\n",
    "### Even more power than echoing out what is in the PEST files, we can use pyemu to add preferred value regularization equations to the recharge and well parameter groups.  Note though, pyemu doesn't call it \"preferred value\"! Rather, it uses the mathematical term \"Zero Order Tikhonov\" so we have to use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pyemu to apply preferred value (aka zero order Tikhonov) to the parameters at the end\n",
    "pyemu.helpers.zero_order_tikhonov(pst,par_groups=[\"rch\",\"w0\",\"w1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that only recharge and well parameters were regularized (i.e., the ones listed at the end of the line of code).\n",
    "\n",
    "##### Let's see how the preferred value equation looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.prior_information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RECALL:  This report does not mean that the PEST control file has been updated! It is simply reporting what is in pyemu's memory block.\n",
    "\n",
    "\n",
    "### Now, let's add preferred difference regularization to the spatially distributed parameters.  Note that preferred value only needed one parameter (the value of that parameter).  A preferred difference regularization constraint involves 2 parameters.  But the spatial distance between any two parameters is not the same - how do we deal?  With  geostatistics! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pyemu.geostats.ExpVario(contribution=1.0,a=2500.0)\n",
    "gs = pyemu.geostats.GeoStruct(variograms=v,nugget=0.0)\n",
    "df_pp = pyemu.pp_utils.pp_tpl_to_dataframe(os.path.join(working_dir,\"hkpp.dat.tpl\"))\n",
    "cov = gs.covariance_matrix(df_pp.x,df_pp.y,df_pp.parnme)\n",
    "pyemu.helpers.first_order_pearson_tikhonov(pst,cov,reset=False,abs_drop_tol=0.1)\n",
    "pst.prior_information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that the preferred difference = 0, which means our preferred difference regularization is really a preferred *homogeneity* condition!\n",
    "\n",
    "\n",
    "\n",
    "### Okay, getting close.  Some housekeeping - we need to change PEST's estimation mode from \"estimation\" to \"regularization\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.pestmode = \"regularization\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And, most importantly we need to see what pyemu has for the all important regularization BIG KNOB, the target objective function - or ``phimlim``.  This is THE ONE INPUT that tells PEST how regularization is enforced.  So let's use pyemu to see what our control file has for ``phimlim``.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the PEST control file defined by pst above, echo out phimlim\n",
    "pst.reg_data.phimlim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's no good - way too low for a final parameter estimation.  But recall our workflow from the Intro to Regularization workbook.  Thisd is just a \"placeholder\" value to ignore soft knowledge and only focus on the best fit.  After the how-low-can-PEST-go run, ``phimlim`` should be set to a larger number, say the number of non-zero weighted obs.  Here we'll explore the effect of ``phimlim`` a bit.  We saw in the unregularized pilot point run, are best ``phi`` was about 120, so let's try doubling that to 240 (just a guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pyemu to set the phimlim to 240\n",
    "pst.reg_data.phimlim = 240\n",
    "# when phimlim changes so should phimaccept, and is usually 5-10% higher than phimlim\n",
    "pst.reg_data.phimaccept = 260\n",
    "#pst.svd_data.maxsing = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we're ready to write all the information that pyemu has in memory to the PEST control file...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.write(os.path.join(working_dir,pst_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can look at the file we just wrote by opening freyberg_pp.pst in the freyberg_pp directory, but here we'll plunge on.  Let's run it - this will again take a little time, watch the run in the terminal window that launched the notebook...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.chdir(working_dir)\n",
    "pyemu.os_utils.start_slaves('.',\"pestpp\",pst_name,num_slaves=15,master_dir='.')\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Okay - let's look at how we did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the reduction of phi by model runs\n",
    "pst.plot(kind=\"phi_progress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report the final phi for the PEST run defined in pst\n",
    "pst.phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "pst.plot(kind=\"1to1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see how the parameter values look.  First, let's take the optimal parameter values from our run and put them through fac2real to make arrays...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(working_dir)\n",
    "pst.parrep(pst_name.replace(\".pst\",\".parb\"))\n",
    "pst.write_input_files()\n",
    "pyemu.geostats.fac2real(\"hkpp.dat\",factors_file=\"hkpp.dat.fac\",out_file=\"hk_layer_1.ref\")\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paru = pd.read_csv(os.path.join(working_dir,pst_name.replace(\".pst\",\".par.usum.csv\")),index_col=0)\n",
    "\n",
    "hk_pars = [p.upper() for p in pst.par_names if p.startswith(\"hk\")]\n",
    "df_hk = df_paru.loc[hk_pars,:]\n",
    "ax = pyemu.plot_utils.plot_summary_distributions(df_hk,label_post=True)\n",
    "mn = np.log10(pst.parameter_data.loc[hk_pars[0].lower(),\"parlbnd\"])\n",
    "mx = np.log10(pst.parameter_data.loc[hk_pars[0].lower(),\"parubnd\"])\n",
    "ax.plot([mn,mn],ax.get_ylim(),\"k--\")\n",
    "ax.plot([mx,mx],ax.get_ylim(),\"k--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not a good sign...lots of parameters are still at their bounds (dashed vertical black lines)...not as many, but still a lot of them.  Let's see what the optimal field look likes...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp = pyemu.pp_utils.pp_tpl_to_dataframe(os.path.join(working_dir,\"hkpp.dat.tpl\"))\n",
    "m = flopy.modflow.Modflow.load(fs.MODEL_NAM,model_ws=working_dir)\n",
    "ax = m.upw.hk[0].plot(colorbar=True,alpha=0.5)\n",
    "ax.scatter(df_pp.x,df_pp.y,marker='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Hmm, let's plot the true field again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.upw.hk[0] = os.path.join(fs.BASE_MODEL_DIR,\"hk.truth.ref\")\n",
    "ax = m.upw.hk[0].plot(colorbar=True,alpha=0.5)\n",
    "ax.scatter(df_pp.x,df_pp.y,marker='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oh no!!!!!  Better but we are still over fit...so let's back off the fit using ``phimilim``.  But first,  let's see how this overfit model did simulating the forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foreu = pd.read_csv(os.path.join(working_dir,pst_name.replace(\".pst\",\".pred.usum.csv\")),index_col=0)\n",
    "figs, axes = pyemu.plot_utils.plot_summary_distributions(df_foreu,subplots=True)\n",
    "for ax in axes:\n",
    "    fname = ax.get_title().lower()\n",
    "    ylim = ax.get_ylim()\n",
    "    v = pst.observation_data.loc[fname,\"obsval\"]\n",
    "    ax.plot([v,v],ylim,\"b--\")\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are doing well with the posterior uncertainty - the shaded area is thinner and higher than the grey dashed prior uncertainty for several forecasts. But, compared to the \"truth\" (vertical blue line), we are not doing well - the model is not reliable for all forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust ``phimlim`` and rerun..\n",
    "\n",
    "### Let's adjust the weights and ``phimlim`` based on how well we fit last time...and see if we can eliminate our overfitting problem.  How will we know we have eliminated it? In the real world, we will never know...\n",
    "\n",
    "### Before changing, let's get a feel for what the model results look like with ``phimlim`` = 250.  So we said wanted our target objective function to be 250.  Where did it end up?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretty much where we should be, but our parameter fit was overfit. What does a Phi of around 250 look like for the observations? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(working_dir,pst_name))\n",
    "pst.res.loc[pst.nnz_obs_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Okay, let's use pyemu to change PHIMLIM, let's double it to 500.  And the last line writes the new PEST control file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.reg_data.phimlim = 500.0\n",
    "pst.reg_data.phimaccept = 550.0\n",
    "pst.reg_data.fracphim = 0.75\n",
    "pst.svd_data.maxsing = 3\n",
    "pst.write(os.path.join(working_dir,pst_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  You can look at the bottom of freyberg_pp.pst to see the change we made, but let's start the run...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(working_dir)\n",
    "pyemu.os_utils.start_slaves('.',\"pestpp\",pst_name,num_slaves=15,master_dir='.')\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.plot(kind=\"phi_progress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(os.path.join(working_dir,pst_name))\n",
    "pst.phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.plot(kind=\"1to1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at the K field again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(working_dir)\n",
    "pst.parrep(pst_name.replace(\".pst\",\".parb\"))\n",
    "pst.write_input_files()\n",
    "pyemu.geostats.fac2real(\"hkpp.dat\",factors_file=\"hkpp.dat.fac\",out_file=\"hk_layer_1.ref\")\n",
    "os.chdir(\"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = flopy.modflow.Modflow.load(fs.MODEL_NAM,model_ws=working_dir)\n",
    "ax = m.upw.hk[0].plot(colorbar=True,alpha=0.5)\n",
    "ax.scatter(df_pp.x,df_pp.y,marker='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## That's much better...let's compare it to the truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.upw.hk[0] = os.path.join(fs.BASE_MODEL_DIR,\"hk.truth.ref\")\n",
    "ax = m.upw.hk[0].plot(colorbar=True,alpha=0.5)\n",
    "ax.scatter(df_pp.x,df_pp.y,marker='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's see how the uncertainty looks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paru = pd.read_csv(os.path.join(working_dir,pst_name.replace(\".pst\",\".par.usum.csv\")),index_col=0)\n",
    "hk_pars = [p.upper() for p in pst.par_names if p.startswith(\"hk\")]\n",
    "df_hk = df_paru.loc[hk_pars,:]\n",
    "ax = pyemu.plot_utils.plot_summary_distributions(df_hk,label_post=True)\n",
    "mn = np.log10(pst.parameter_data.loc[hk_pars[0].lower(),\"parlbnd\"])\n",
    "mx = np.log10(pst.parameter_data.loc[hk_pars[0].lower(),\"parubnd\"])\n",
    "ax.plot([mn,mn],ax.get_ylim(),\"k--\")\n",
    "ax.plot([mx,mx],ax.get_ylim(),\"k--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahhh yeah! Lot fewer pilot points at the bounds.  What about the forecasts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, axes = pyemu.plot_utils.plot_summary_distributions(os.path.join(working_dir,\n",
    "                    pst_name.replace(\".pst\",\".pred.usum.csv\")),subplots=True)\n",
    "for ax in axes:\n",
    "    fname = ax.get_title()\n",
    "    pyemu.plot_utils.plot_summary_distributions(df_foreu.loc[[fname],:],ax=ax,pt_color='g')\n",
    "    fname = fname.lower()\n",
    "    ylim = ax.get_ylim()\n",
    "    v = pst.observation_data.loc[fname,\"obsval\"]\n",
    "    ax.plot([v,v],ylim,\"b--\")\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Green shading is the previous run with PHIMLIM = 250; blue shading is the new run with PHIMLIM = 500.  The new run now brackets the \"truth\" with significant probability for most forecast (FINALLY!!!). So, even though we aren't fitting the observations as well, we are doing much better from a model forecast reliability stand point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
