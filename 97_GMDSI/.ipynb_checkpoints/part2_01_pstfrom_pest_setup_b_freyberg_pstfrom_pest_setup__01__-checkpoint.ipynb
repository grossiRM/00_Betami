{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys ; import os ; import platform ; from pathlib import Path ; import shutil\n",
    "import warnings ; warnings.filterwarnings(\"ignore\") ; warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "import pandas as pd ; import numpy as np ; import matplotlib.pyplot as plt; import pyemu ; import flopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_ws1   = tmp_d = Path('E:\\\\15_REPOS\\\\00_BETAMI\\\\97_GMDSI\\\\models\\\\monthly_model_files_1lyr_newstress')  ; sim_name = \"freyberg_mf6\"\n",
    "sim_ws    = Path(\"./w_part2_01\")                                                                           ; sim_ws.mkdir(exist_ok=True) \n",
    "exe_name  = 'E:\\\\15_REPOS\\\\00_BETAMI\\\\97_GMDSI\\\\00_bin\\\\mf6.exe'  ;  exe_name2  = 'E:\\\\15_REPOS\\\\00_BETAMI\\\\97_GMDSI\\\\00_bin\\\\mp7.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mf6.exe\n",
      "mp7.exe freyberg_mp.mpsim\n"
     ]
    }
   ],
   "source": [
    "shutil.copytree(sim_ws1, sim_ws, dirs_exist_ok=True) ; sim = flopy.mf6.MFSimulation.load(sim_ws=sim_ws,verbosity_level=0) #; sim.set_sim_path(sim_ws) \n",
    "sim.run_simulation() ; pyemu.os_utils.run(\"mf6\",cwd=sim_ws) ; pyemu.os_utils.run(r'mp7 freyberg_mp.mpsim', cwd=sim_ws) ;gwf = sim.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   could not remove start_datetime\n",
      "xul:0; yul:10000; rotation:0; proj4_str:None; units:meters; lenuni:2; length_multiplier:1.0\n"
     ]
    }
   ],
   "source": [
    "sr = pyemu.helpers.SpatialReference.from_namfile(os.path.join(sim_ws, \"freyberg6.nam\"),delr=gwf.dis.delr.array, delc=gwf.dis.delc.array); print(sr)\n",
    "template_ws = os.path.join(sim_ws,\"freyberg6_template\")      ; start_datetime=\"1-1-2008\"            # PEST Template\n",
    "pf = pyemu.utils.PstFrom(original_d=sim_ws, new_d=template_ws, \n",
    "                         remove_existing=True, longnames=True, spatial_reference=sr, zero_based=False, start_datetime=start_datetime, echo=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0,\"..\")\n",
    "import herebedragons as hbd\n",
    "hbd.prep_bins(template_ws)\n",
    "#hbd.prep_deps(sim_ws1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "os.listdir(template_ws); \n",
    "for i in gwf.obs:     print(i.output.obs_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(os.path.join(template_ws,\"heads.csv\") ,index_col=0)                                ; df1.to_csv (sim_ws/\"01_H.csv\")  \n",
    "df2 = pd.read_csv(os.path.join(template_ws,\"sfr.csv\")   ,index_col=0)                                ; df2.to_csv (sim_ws/\"02_SFR.csv\") \n",
    "\n",
    "hds_df1 = pf.add_observations (\"heads.csv\", insfile=\"heads.csv.ins\", index_cols=\"time\", use_cols=list(df1.columns.values), prefix=\"hds\") \n",
    "sfr_df2 = pf.add_observations (\"sfr.csv\"  , insfile=\"sfr.csv.ins\"  , index_cols=\"time\", use_cols=list(df2.columns.values), prefix=\"sfr\")  \n",
    "p1_ins = [f for f in os.listdir(template_ws) if f.endswith(\".ins\")]; print('list', p1_ins)           ; hds_df1.to_csv (sim_ws/\"03ab_hds_df1.csv\")  ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1 layer - transient** - Hydraulic properties **(Kh, Kv, Ss, Sy)** varing in space\n",
    "#### **GHB** - BC1 - constant over time, but vary spatially\n",
    "#### **SFR** - BC2 - inflow varies over time\n",
    "#### **WEL** - BC3 - Pumping rates of individual wells are uncertain in space and and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_grid   = pyemu.geostats.ExpVario (contribution=1.0, a=1000  , anisotropy=1.0, bearing=0.0)  \n",
    "v_pp     = pyemu.geostats.ExpVario (contribution=1.0, a=15000 , anisotropy=1.0, bearing=0.0 ) \n",
    "v_time   = pyemu.geostats.ExpVario (contribution=1.0, a=60    , anisotropy=1.0, bearing=0.0 ) \n",
    "grid_gs     = pyemu.geostats.GeoStruct (variograms=v_grid     , transform='log')\n",
    "pp_gs       = pyemu.geostats.GeoStruct (variograms=v_pp       , transform='log') \n",
    "temporal_gs = pyemu.geostats.GeoStruct (variograms=v_time     , transform='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_plot(ax):\n",
    "    aa = grid_gs.plot(ax=ax1)  ; ab = pp_gs.plot  (ax=ax2)  ; ac = temporal_gs.plot(ax=ax3)\n",
    "plt.figure(figsize=(12,6))\n",
    "ax1 = plt.subplot2grid((3, 3), (0, 0), colspan=1, rowspan=1) ; ax1.text(2000,.5  ,\"Grid_Variogram\",ha=\"center\",fontsize=10)\n",
    "ax2 = plt.subplot2grid((3, 3), (0, 1), colspan=1, rowspan=1) ; ax2.text(30000,.5 ,\"v_pp_Variogram\",ha=\"center\",fontsize=10)\n",
    "ax3 = plt.subplot2grid((3, 3), (0, 2), colspan=1, rowspan=1) ; ax3.text(120,.5   ,\"time_Variogram\",ha=\"center\",fontsize=10)\n",
    "beta_plot(ax1) ; beta_plot(ax2) ; beta_plot(ax3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"npf_k_\"  ; files = [f for f in os.listdir(template_ws) if tag in f.lower() and f.endswith(\".txt\")]  ; print(files)\n",
    "k1 = np.loadtxt(os.path.join(template_ws,'freyberg6.npf_k_layer1.txt')); print(k1.shape) ; k1 = pd.DataFrame(k1)    ; k1.to_csv (sim_ws/ \"04_k1.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> **coarse scale** </font> constant K, single layer <font color='blue'> **coarse scale** </font> pilot points <font color='blue'> **coarse scale** </font> a unique K each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ib = gwf.dis.idomain.array[0]  #; plt.imshow(ib)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 'freyberg6.npf_k_layer1.txt'\n",
    "df_gr = pf.add_parameters(f,zone_array=ib, par_type=\"grid\", geostruct=grid_gs, par_name_base=f.split('.')[1].replace(\"_\",\"\")+\"gr\", \n",
    "                          pargp=f.split('.')[1].replace(\"_\",\"\")+\"gr\", lower_bound=0.2, upper_bound=5.0, ult_ubound=100, ult_lbound=0.01 )\n",
    "df_gr = pd.DataFrame(df_gr)    ; df_gr.to_csv (sim_ws/ \"05a_df_gr.csv\")  ; df_gr.head(2); #[f for f in os.listdir(template_ws) if f.endswith(\".tpl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp = pf.add_parameters(f,zone_array=ib,par_type=\"pilotpoints\",geostruct=pp_gs,par_name_base=f.split('.')[1].replace(\"_\",\"\")+\"pp\",\n",
    "                          pargp=f.split('.')[1].replace(\"_\",\"\")+\"pp\",lower_bound=0.2,upper_bound=5.0,ult_ubound=100, ult_lbound=0.01,\n",
    "                          pp_space=5) \n",
    "df_pp = pd.DataFrame(df_pp)    ; df_pp.to_csv (sim_ws/ \"05b_df_pp.csv\"); print('pilot points') \n",
    "# fig,ax = plt.subplots(1,1,figsize=(2,3)) ; ax.set_aspect(\"equal\") ; ax.pcolormesh(sr.xcentergrid, sr.ycentergrid,ib) ; ax.scatter(df_pp.x,df_pp.y)\n",
    "df_cst = pf.add_parameters(f,zone_array=ib,par_type=\"constant\",geostruct=grid_gs,par_name_base=f.split('.')[1].replace(\"_\",\"\")+\"cn\",\n",
    "                           pargp=f.split('.')[1].replace(\"_\",\"\")+\"cn\",lower_bound=0.2,upper_bound=5.0,ult_ubound=100, ult_lbound=0.01)\n",
    "df_cst = pd.DataFrame(df_cst)    ; df_cst.to_csv (sim_ws/ \"05c_df_cte.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pf.add_observations(f,prefix=\"hk\",zone_array=ib) ; df.to_csv (sim_ws/ \"06_HK_as_observations.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> **parameterization** </font> ...again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mult_pars(f, lb=0.2, ub=5.0, ulb=0.01, uub=100, add_coarse=True):\n",
    "    if isinstance(f,str):    base  = f.split   (\".\")[1].replace(\"_\",\"\")\n",
    "    else:                    base  = f[0].split(\".\")[1]\n",
    "    pf.add_parameters(f,zone_array = ib,par_type=\"grid\"  ,geostruct=grid_gs, par_name_base=base+\"gr\", pargp=base+\"gr\", lower_bound=lb, \n",
    "                      upper_bound  = ub, ult_ubound=uub  ,ult_lbound=ulb)\n",
    "    pf.add_parameters(f,zone_array = ib,par_type=\"pilotpoints\",geostruct=pp_gs,par_name_base=base+\"pp\",pargp=base+\"pp\",lower_bound=lb, \n",
    "                      upper_bound  = ub,ult_ubound=uub   ,ult_lbound=ulb ,pp_space=5) \n",
    "    if add_coarse==True:\n",
    "        pf.add_parameters(f,zone_array=ib,par_type=\"constant\",geostruct=grid_gs,par_name_base=base+\"cn\",pargp=base+\"cn\",lower_bound=lb, \n",
    "                          upper_bound=ub,ult_ubound=uub, ult_lbound=ulb)                       ; return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qde_PAR1 = len([f for f in os.listdir(template_ws) if f.endswith(\".tpl\")]); print('PAR_groups_first_batch_K=',qde_PAR1)\n",
    "[f for f in os.listdir(template_ws) if f.endswith(\".tpl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag = \"sto_ss\"       ; files =         [f for f in  os.listdir(template_ws) if tag in f.lower() and f.endswith(\".txt\")]\n",
    "#for f in files[1:]:    add_mult_pars   (f, lb=0.2 , ub=5.0,   ulb=1e-7 ,uub=1e-3)\n",
    "tag = \"sto_sy\"       ; files =         [f for f in  os.listdir(template_ws) if tag in f.lower() and f.endswith(\".txt\")]\n",
    "f = files[0]         ; add_mult_pars   (f, lb=0.2 , ub=5.0,   ulb=0.01 ,uub=0.4)\n",
    "tag = \"ne_\"          ; files =         [f for f in os.listdir(template_ws) if tag in f.lower() and f.endswith(\".txt\")]\n",
    "for f in files:        add_mult_pars   (f, lb=0.2 , ub=5.0,   ulb=0.01 ,uub=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qde_PAR2 = len([f for f in os.listdir(template_ws) if f.endswith(\".tpl\")]); print(qde_PAR1,'+','PAR_groups_second_batch_sto(SsSy,)_ne_=',qde_PAR2)\n",
    "#[f for f in os.listdir(template_ws) if f.endswith(\".tpl\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> **recharge | space and time uncertainties** </font> ... 1ยบ cte in space varing in time; 2ยบ cte in time varing in space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dts = pd.to_datetime(start_datetime) + pd.to_timedelta(np.cumsum(sim.tdis.perioddata.array[\"perlen\"]),unit='d')\n",
    "dts2 = pd.DataFrame(dts)    ; dts2.to_csv (sim_ws/ \"07_HK_Perlen.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"rch_recharge\"   ;   files = [f for f in os.listdir(template_ws) if tag in f.lower() and f.endswith(\".txt\")]\n",
    "sp = [int(f.split(\".\")[1].split('_')[-1]) for f in files]    \n",
    "dd = {s:f for s,f in zip(sp,files)}   ;  sp.sort()                  ; files = [dd[s] for s in sp]                                # dd\n",
    "print(qde_PAR2,'+')                                  ; add_mult_pars (files, lb=0.2, ub=5.0, ulb=0, uub=1e-3, add_coarse=False)    # fron function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qde_PAR3 = len([f for f in os.listdir(template_ws) if f.endswith(\".tpl\")]); print(qde_PAR2,'+2', 'PAR_groups_third_batch_RCH1(space)=',qde_PAR3)\n",
    "#[f for f in os.listdir(template_ws) if f.endswith(\".tpl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffiles = pd.DataFrame(files) ; ffiles.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:   \n",
    "    kper = int(f.split('.')[1].split('_')[-1]) - 1  \n",
    "    pf.add_parameters(filenames=f  ,zone_array=ib,par_type=\"constant\",par_name_base=f.split('.')[1]+\"tcn\",pargp=f.split('.')[1]+\"tcn\",\n",
    "                      lower_bound=0.5, upper_bound=1.5,ult_ubound=1e-3, ult_lbound=0,datetime=dts[kper], geostruct=temporal_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qde_PAR4 = len([f for f in os.listdir(template_ws) if f.endswith(\".tpl\")]); print(qde_PAR3,'+25  ''PAR_groups_fourth_batch_RCH_2(time)=',qde_PAR4)\n",
    "#[f for f in os.listdir(template_ws) if f.endswith(\".tpl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"ghb_stress_period_data\"    ; files = [f for f in os.listdir(template_ws) if tag in f.lower() and f.endswith(\".txt\")]; print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"ghb_stress_period_data\"    ; files = [f for f in os.listdir(template_ws) if tag in f.lower() and f.endswith(\".txt\")]\n",
    "for f in files:\n",
    "    name = 'ghbcond'\n",
    "    pf.add_parameters(f,par_type=\"grid\",geostruct=grid_gs,par_name_base=name+\"gr\",pargp=name+\"gr\",index_cols=[0,1,2], use_cols=[4],\n",
    "                      lower_bound=0.1,upper_bound=10.0)\n",
    "    pf.add_parameters(f,par_type=\"constant\",geostruct=grid_gs,par_name_base=name+\"cn\",pargp=name+\"cn\",index_cols=[0,1,2],use_cols=[4],\n",
    "                      lower_bound=0.1,upper_bound=10.0,ult_lbound=0.01, ult_ubound=100) \n",
    "    name = 'ghbhead'\n",
    "    pf.add_parameters(f,par_type=\"grid\",geostruct=grid_gs,par_name_base=name+\"gr\",pargp=name+\"gr\",index_cols=[0,1,2],use_cols=[3],\n",
    "                      lower_bound=-2.0,upper_bound=2.0,par_style=\"a\", transform=\"none\", ult_lbound=32.5, ult_ubound=42) \n",
    "    pf.add_parameters(f,par_type=\"constant\",geostruct=grid_gs,par_name_base=name+\"cn\",pargp=name+\"cn\",index_cols=[0,1,2],use_cols=[3],\n",
    "                      lower_bound=-2.0,upper_bound=2.0, par_style=\"a\", transform=\"none\",ult_lbound=32.5, ult_ubound=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qde_PAR5 = len([f for f in os.listdir(template_ws) if f.endswith(\".tpl\")]); print(qde_PAR4,'+4  ''PAR_groups_fourth_batch_GHB=',qde_PAR5)\n",
    "#[f for f in os.listdir(template_ws) if f.endswith(\".tpl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(template_ws) if \"wel_stress_period_data\" in f and f.endswith(\".txt\")]; ffiles = pd.DataFrame(files) ; ffiles.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(template_ws) if \"wel_stress_period_data\" in f and f.endswith(\".txt\")]\n",
    "sp = [int(f.split(\".\")[1].split('_')[-1]) for f in files]      ; d = {s:f for s,f in zip(sp,files)}     ; sp.sort() ; files = [d[s] for s in sp]\n",
    "for f in files:\n",
    "    kper = int(f.split('.')[1].split('_')[-1]) - 1  \n",
    "    pf.add_parameters(filenames=f,index_cols=[0,1,2]    ,use_cols=[3]       ,par_type=\"constant\" ,par_name_base=\"welcst\",pargp=\"welcst\", \n",
    "                      upper_bound = 4, lower_bound=0.25 ,datetime=dts[kper] ,geostruct=temporal_gs)\n",
    "    pf.add_parameters(filenames=f,index_cols=[0,1,2]    ,use_cols=[3]       , par_type=\"grid\"    ,par_name_base=\"welgrd\",pargp=\"welgrd\", \n",
    "                      upper_bound = 4, lower_bound=0.25 ,datetime=dts[kper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qde_PAR6 = len([f for f in os.listdir(template_ws) if f.endswith(\".tpl\")]); print(qde_PAR5,'+25|+25  ''PAR_groups_fifth_batch_Wel(cte|grid)=',qde_PAR6)\n",
    "#[f for f in os.listdir(template_ws) if f.endswith(\".tpl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(template_ws) if \"sfr_packagedata\" in f.lower() and f.endswith(\".txt\")] ; assert len(files) == 1 ; # print(files)\n",
    "f = files[0]  ; name = \"sfrcond\"\n",
    "pf.add_parameters(f,par_type=\"grid\",geostruct=grid_gs,par_name_base=name+\"gr\",pargp=name+\"gr\",index_cols=[0,2,3],use_cols=[9],\n",
    "                  lower_bound=0.1,upper_bound=10.0)\n",
    "pf.add_parameters(f,par_type=\"constant\",geostruct=grid_gs,par_name_base=name+\"cn\",pargp=name+\"cn\",index_cols=[0,2,3],use_cols=[9],\n",
    "                  lower_bound=0.1,upper_bound=10.0,ult_lbound=0.001, ult_ubound=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qde_PAR7 = len([f for f in os.listdir(template_ws) if f.endswith(\".tpl\")]); print(qde_PAR6,'+1+1  ''PAR_groups_sixth_batch_SFR=',qde_PAR7)\n",
    "# [f for f in os.listdir(template_ws) if f.endswith(\".tpl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(template_ws) if \"sfr_perioddata\" in f and f.endswith(\".txt\")]\n",
    "sp = [int(f.split(\".\")[1].split('_')[-1]) for f in files]    ; d = {s:f for s,f in zip(sp,files)}   ; sp.sort()  ; files = [d[s] for s in sp]\n",
    "for f in files:\n",
    "    kper = int(f.split('.')[1].split('_')[-1]) - 1  \n",
    "    pf.add_parameters(filenames=f,index_cols=[0], use_cols=[2],par_type=\"grid\", \n",
    "                      par_name_base=\"sfrgr\",pargp=\"sfrgr\", upper_bound = 10, lower_bound=0.1, datetime=dts[kper], geostruct=temporal_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qde_PAR8 = len([f for f in os.listdir(template_ws) if f.endswith(\".tpl\")]); print(qde_PAR7,'+1  ''PAR_groups_fifth_batch_Wel=',qde_PAR8)\n",
    "# [f for f in os.listdir(template_ws) if f.endswith(\".tpl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(template_ws) if \"ic_strt\" in f and f.endswith(\".txt\")]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    base = f.split(\".\")[1].replace(\"_\",\"\")\n",
    "    df = pf.add_parameters(f,par_type=\"grid\",par_style=\"d\",pargp=base,par_name_base=base,upper_bound=50,lower_bound=15,zone_array=ib,transform=\"none\")\n",
    "    df2 = pd.DataFrame(df)    ; df2.to_csv (sim_ws/ \"08_IC.csv\")  ; print('IC40x20x1-(inactives_ibound) x TDIS' ,df.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.tail(2); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qde_PAR9 = len([f for f in os.listdir(template_ws) if f.endswith(\".tpl\")]); print(qde_PAR8,'+1  ''PAR_groups_fifth_batch_IC=',qde_PAR9)\n",
    "#[f for f in os.listdir(template_ws) if f.endswith(\".tpl\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> **PEST \"model\"** </font> ... MODFLOW + PAR + OBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pf.build_pst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f for f in os.listdir(template_ws) if f.endswith(\".py\") or f.endswith(\".pst\") ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'> **Second part!**  </font> ... after 38 commands and inspections ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A list of system commands which will be executed in sequence.**  Python functions that run before or after the system commands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.mod_sys_cmds.append(\"mf6\") ; pf.mod_sys_cmds.append(\"mp7 freyberg_mp.mpsim\") ; pf.mod_sys_cmds ; pst = pf.build_pst()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Extract the final simulated water level for all model cells for the last stress period from the MF6 binary headsave file and save them to ASCII format\n",
    "Extract the global water budget info from the MF6 listing file and store it in dataframes\n",
    "... setup pest observations for those ASCII head arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.add_py_function(\"helpers.py\",\"extract_hds_arrays_and_list_dfs()\",is_pre_cmd=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers\n",
    "helpers.test_extract_hds_arrays(template_ws)\n",
    "files = [f for f in os.listdir(template_ws) if f.startswith(\"hdslay\")]  # files\n",
    "for f in files: pf.add_observations(f,prefix=f.split(\".\")[0],obsgp=f.split(\".\")[0])\n",
    "for f in [\"inc.csv\",\"cum.csv\"]:\n",
    "    df = pd.read_csv(os.path.join(template_ws,f),index_col=0)\n",
    "    pf.add_observations(f,index_cols=[\"totim\"],use_cols=list(df.columns.values), prefix=f.split('.')[0],obsgp=f.split(\".\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpers.process_secondary_obs(ws=template_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[f for f in os.listdir(template_ws) if f.endswith(\".csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.add_py_function(\"helpers.py\", \"process_secondary_obs(ws='.')\", is_pre_cmd=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join (template_ws, \"sfr.tdiff.csv\"), index_col=0)\n",
    "_  = pf.add_observations      (\"sfr.tdiff.csv\"  , insfile=\"sfr.tdiff.csv.ins\"  , index_cols=\"time\", use_cols=list(df.columns.values), prefix=\"sfrtd\") \n",
    "df = pd.read_csv(os.path.join (template_ws, \"heads.tdiff.csv\"), index_col=0)\n",
    "_  = pf.add_observations      (\"heads.tdiff.csv\", insfile=\"heads.tdiff.csv.ins\", index_cols=\"time\", use_cols=list(df.columns.values), prefix=\"hdstd\") \n",
    "pst = pf.build_pst()          #_ = [print(line.rstrip()) for line in open(os.path.join(template_ws,\"forward_run.py\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pst.observation_data  ; obs.to_csv (sim_ws/ \"09_OBS_2.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> **OBS Weights, PAR bounds, ctrls     ...**  </font> *.ins, weights, PAR group INCTYP's and forecasts  `    `  OBS particles end time and status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"freyberg_mp.mpend\" ; ins_file = out_file + \".ins\"\n",
    "with open(os.path.join(template_ws, ins_file),'w') as f:     f.write(\"pif ~\\n\")  ; f.write(\"l7 w w w w !part_status! w w !part_time!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.add_observations(ins_file=os.path.join(template_ws, ins_file),out_file=os.path.join(template_ws, out_file),pst_path='.')\n",
    "obs=pst.observation_data            ;obs.loc[obs.obsnme=='part_status', 'obgnme']='part'   ;obs.loc[obs.obsnme=='part_time','obgnme']='part' \n",
    "obs.to_csv (sim_ws/ \"10_OBS_3.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> **Offset\" PAR values and bounds... or...  use \"absolute\" increment types (INCTYP)**  </font> \n",
    "INCTYP 'absolute'. DERINC as 0.01 ... for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_pargps = [i for i in pst.adj_par_groups if 'head' in i]  ; head_pargps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.parameter_groups.loc[head_pargps, 'inctyp'] = 'absolute'\n",
    "par = pst.parameter_data                        ; par_names = par.loc[par.parval1==0].parnme    # ; par.to_csv (sim_ws/ \"11_PAR.csv\") \n",
    "offset=-10 ;par.loc[par_names,'offset']=offset  ; par.loc[par_names,['parval1','parlbnd','parubnd']]-=offset   ; par.to_csv (sim_ws/ \"11_PAR.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> **forecasts as \"observations\" in the control file** </font>  ...our interest this time: ... forecast:\n",
    "\n",
    " - groundwater level in the upper layer at row 9 and column 1 (site named \"trgw-0-9-1\") in stress period 22 (time=640);\n",
    " - the \"tailwater\" surface-water/groundwater exchange during stress period 13 (time=367); and\n",
    " - the \"headwater\" surface-water/groundwater exchange at stress period 22 (time=640).\n",
    " - the particle travel time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts =['oname:sfr_otype:lst_usecol:tailwater_time:4383.5'   ,'oname:sfr_otype:lst_usecol:headwater_time:4383.5',\n",
    "            'oname:hds_otype:lst_usecol:trgw-0-9-1_time:4383.5'  ,'part_time'] \n",
    "fobs = obs.loc[forecasts,:]   ; fobs2 = pd.DataFrame(fobs) ; fobs.to_csv (sim_ws/ \"12_forecasts.csv\")   ; pst.pestpp_options['forecasts'] = forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.write(os.path.join(template_ws, 'freyberg_mf6.pst'),version=2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.noptmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.run('pestpp-glm freyberg_mf6.pst', cwd = template_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we assigned observation values generated from the \"base model run\"? If we setup everything correctly, this means that PEST should have obtained residuals very close to zero. As mentioned, this is a good way to check for problems early on.\n",
    "\n",
    "Let's check the Phi recorded in the *.iobj file (could also check the *.rec or *.rei files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iobj = pd.read_csv(os.path.join(template_ws, 'freyberg_mf6.iobj'))\n",
    "#iobj.total_phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Sweet! Zero. All is well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior Parameter Covariance Matrix\n",
    "\n",
    "One the major reasons `PstFrom` was built is to help with building the Prior - both covariance matrix and ensemble - with geostatistical correlation.  Remember all that business above related to geostatistical structures and correlations?  This is where it pays off.\n",
    "\n",
    "Let's see how this works.  For cases with less than about 30,000 parameters, we can actually generate and visualize the prior parameter covariance matrix.  If you have more parameters, this matrix may not fit in memory.  But, not to worry, `PstFrom` has some trickery to help generate the geostatistical prior ensemble even in cases where the number of parameters is greater than 30,000. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the prior covariance matrix and store it as a compresed bianry file (otherwise it can get huge!)\n",
    "# depending on your machine, this may take a while...\n",
    "if pf.pst.npar < 35000:  #if you have more than about 35K pars, the cov matrix becomes hard to handle\n",
    "    cov = pf.build_prior(fmt='coo', filename=os.path.join(template_ws,\"prior_cov.jcb\"))\n",
    "    # and take a peek at a slice of the matrix\n",
    "    try: \n",
    "        x = cov.x.copy()\n",
    "        x[x==0] = np.NaN\n",
    "        plt.imshow(x[:1000,:1000])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "snap!  That big block must be a grid-scale parameter group..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov.row_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now generate a prior parameter ensemble. This step is relevant for using pestpp-ies in subsequent tutorials. Note: you do not have to call `build_prior()` before calling `draw()`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = pf.draw(num_reals=1000, use_specsim=True) # draw parameters from the prior distribution\n",
    "pe.enforce() # enforces parameter bounds\n",
    "pe.to_binary(os.path.join(template_ws,\"prior_pe.jcb\")) #writes the paramter ensemble to binary file\n",
    "assert pe.shape[1] == pst.npar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now test-run one of these geostatistical realizations (always a good idea!).  We do this by replacing the `parval1` values in the control with a row from `pe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.parameter_data.loc[:,\"parval1\"] = pe.loc[pe.index[0],pst.par_names].values\n",
    "pst.parameter_data.parval1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.noptmax = 0\n",
    "pst.write(os.path.join(template_ws,\"test.pst\"),version=2)\n",
    "pyemu.os_utils.run(\"pestpp-glm test.pst\",cwd=template_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all went well, that's it! The PEST-interface is setup, tested and we have our prior prepared. We should be good to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Understanding Multiplier-Parameters\n",
    "\n",
    "Now the multiplier files in the `template_ws/mult` folder and the MF6 input files in the `template_ws` folder contain the values corresponding to this realization, so we can visualize the multiplier parameter process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(template_ws,\"mult2model_info.csv\"))\n",
    "kh1_df = df.loc[df.model_file.str.contains(\"npf_k_layer1\"),:]\n",
    "kh1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_arr = np.loadtxt(os.path.join(template_ws,kh1_df.org_file.iloc[0]))\n",
    "inp_arr = np.loadtxt(os.path.join(template_ws,kh1_df.model_file.iloc[0]))\n",
    "mlt_arrs = [np.loadtxt(os.path.join(template_ws,afile)) for afile in kh1_df.mlt_file]\n",
    "arrs = [org_arr]\n",
    "arrs.extend(mlt_arrs)\n",
    "arrs.append(inp_arr)\n",
    "names = [\"org\"]\n",
    "names.extend([mf.split('.')[0].split('_')[-1] for mf in kh1_df.mlt_file])\n",
    "names.append(\"MF6 input\")\n",
    "fig,axes = plt.subplots(1,kh1_df.shape[0]+2,figsize=(5*kh1_df.shape[0]+2,5))\n",
    "for i,ax in enumerate(axes.flatten()):\n",
    "    arr = np.log10(arrs[i])\n",
    "    arr[ib==0] = np.NaN\n",
    "    cb = ax.imshow(arr)\n",
    "    plt.colorbar(cb,ax=ax)\n",
    "    ax.set_title(names[i],loc=\"left\")\n",
    "plt.tight_layout()    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can see the difference the pilot point geostructure makes compared to the grid-scale geostructure.  The pilot point array has a much stronger spatial correlation (over a larger distance) than the grid-scale..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, what's up with all these new files and folders? We can trace through them to see how multipliers are applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(url='./pest_flow2.gif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
